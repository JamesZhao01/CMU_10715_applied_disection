{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\James\\anaconda3\\envs\\cmu_10715_applied\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Stolen from docs\n",
    "- https://huggingface.co/datasets/narrativeqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset narrativeqa (C:/Users/James/.cache/huggingface/datasets/narrativeqa/default/0.0.0/daef7ccc51ec258bef464658d11751bb20f033da9b4c219fd84563b3a4af0422)\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"narrativeqa\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' The play begins with three pages disputing over the black cloak usually worn by the actor who delivers the prologue. They draw lots for the cloak, and one of the losers, Anaides, starts telling the audience what happens in the play to come; the others try to suppress him, interrupting him and putting their hands over his mouth. Soon they are fighting over the cloak and criticizing the author and the spectators as well.\\nIn the play proper, the goddess Diana, also called Cynthia, has ordained a \"solemn revels\" in the valley of Gargaphie in Greece. The gods Cupid and Mercury appear, and they too start to argue. Mercury has awakened Echo, who weeps for Narcissus, and states that a drink from Narcissus\\'s spring causes the drinkers to \"Grow dotingly enamored of themselves.\" The courtiers and ladies assembled for the Cynthia\\'s revels all drink from the spring.\\nAsotus, a foolish spendthrift who longs to become a courtier and a master of fashion and manners, also drinks from the spring; emboldened by vanity and self-love, he challenges all comers to a competition of \"court compliment.\" The competition is held, in four phases, and the courtiers are beaten. Two symbolic masques are performed within the play for the assembled revelers. At their conclusion, Cynthia (representing Queen Elizabeth) has the dancers unmask and shows that vices have masqueraded as virtues. She sentences them to make reparation and to purify themselves by bathing in the spring at Mount Helicon.\\nThe figure of Actaeon in the play may represent Robert Devereux, 2nd Earl of Essex, while Cynthia\\'s lady in waiting Arete may be Lucy, Countess of Bedford, one of Elizabeth\\'s ladies in waiting as well as Jonson\\'s patroness.\\nThe play is notably rich in music, as is typical for the theatre of the boys\\' companies, which originated as church choirs.', 'tokens': ['The', 'play', 'begins', 'with', 'three', 'pages', 'disputing', 'over', 'the', 'black', 'cloak', 'usually', 'worn', 'by', 'the', 'actor', 'who', 'delivers', 'the', 'prologue', '.', 'They', 'draw', 'lots', 'for', 'the', 'cloak', ',', 'and', 'one', 'of', 'the', 'losers', ',', 'Anaides', ',', 'starts', 'telling', 'the', 'audience', 'what', 'happens', 'in', 'the', 'play', 'to', 'come', ';', 'the', 'others', 'try', 'to', 'suppress', 'him', ',', 'interrupting', 'him', 'and', 'putting', 'their', 'hands', 'over', 'his', 'mouth', '.', 'Soon', 'they', 'are', 'fighting', 'over', 'the', 'cloak', 'and', 'criticizing', 'the', 'author', 'and', 'the', 'spectators', 'as', 'well', '.', 'In', 'the', 'play', 'proper', ',', 'the', 'goddess', 'Diana', ',', 'also', 'called', 'Cynthia', ',', 'has', 'ordained', 'a', 'solemn', 'revels', 'in', 'the', 'valley', 'of', 'Gargaphie', 'in', 'Greece', '.', 'The', 'gods', 'Cupid', 'and', 'Mercury', 'appear', ',', 'and', 'they', 'too', 'start', 'to', 'argue', '.', 'Mercury', 'has', 'awakened', 'Echo', ',', 'who', 'weeps', 'for', 'Narcissus', ',', 'and', 'states', 'that', 'a', 'drink', 'from', 'Narcissus', 's', 'spring', 'causes', 'the', 'drinkers', 'to', 'Grow', 'dotingly', 'enamored', 'of', 'themselves', '.', 'The', 'courtiers', 'and', 'ladies', 'assembled', 'for', 'the', 'Cynthia', 's', 'revels', 'all', 'drink', 'from', 'the', 'spring', '.', 'Asotus', ',', 'a', 'foolish', 'spendthrift', 'who', 'longs', 'to', 'become', 'a', 'courtier', 'and', 'a', 'master', 'of', 'fashion', 'and', 'manners', ',', 'also', 'drinks', 'from', 'the', 'spring', ';', 'emboldened', 'by', 'vanity', 'and', 'self-love', ',', 'he', 'challenges', 'all', 'comers', 'to', 'a', 'competition', 'of', 'court', 'compliment', '.', 'The', 'competition', 'is', 'held', ',', 'in', 'four', 'phases', ',', 'and', 'the', 'courtiers', 'are', 'beaten', '.', 'Two', 'symbolic', 'masques', 'are', 'performed', 'within', 'the', 'play', 'for', 'the', 'assembled', 'revelers', '.', 'At', 'their', 'conclusion', ',', 'Cynthia', '(', 'representing', 'Queen', 'Elizabeth', ')', 'has', 'the', 'dancers', 'unmask', 'and', 'shows', 'that', 'vices', 'have', 'masqueraded', 'as', 'virtues', '.', 'She', 'sentences', 'them', 'to', 'make', 'reparation', 'and', 'to', 'purify', 'themselves', 'by', 'bathing', 'in', 'the', 'spring', 'at', 'Mount', 'Helicon', '.', 'The', 'figure', 'of', 'Actaeon', 'in', 'the', 'play', 'may', 'represent', 'Robert', 'Devereux', ',', '2nd', 'Earl', 'of', 'Essex', ',', 'while', 'Cynthia', 's', 'lady', 'in', 'waiting', 'Arete', 'may', 'be', 'Lucy', ',', 'Countess', 'of', 'Bedford', ',', 'one', 'of', 'Elizabeth', 's', 'ladies', 'in', 'waiting', 'as', 'well', 'as', 'Jonson', 's', 'patroness', '.', 'The', 'play', 'is', 'notably', 'rich', 'in', 'music', ',', 'as', 'is', 'typical', 'for', 'the', 'theatre', 'of', 'the', 'boys', \"'\", 'companies', ',', 'which', 'originated', 'as', 'church', 'choirs', '.'], 'url': \"http://en.wikipedia.org/wiki/Cynthia's_Revels\", 'title': \"Cynthia's Revels\"}\n"
     ]
    }
   ],
   "source": [
    "print(ds[0][\"document\"][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\James\\anaconda3\\envs\\cmu_10715_applied\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:217: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'sentencepiece_model_pb2' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\James\\Desktop\\projects\\cmu\\CMU_10715_applied_disection\\qa\\narrative_qa.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/James/Desktop/projects/cmu/CMU_10715_applied_disection/qa/narrative_qa.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m T5Tokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mt5-base\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/James/Desktop/projects/cmu/CMU_10715_applied_disection/qa/narrative_qa.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m T5ForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mt5-base\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\cmu_10715_applied\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1854\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1851\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1852\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m from cache at \u001b[39m\u001b[39m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_from_pretrained(\n\u001b[0;32m   1855\u001b[0m     resolved_vocab_files,\n\u001b[0;32m   1856\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m   1857\u001b[0m     init_configuration,\n\u001b[0;32m   1858\u001b[0m     \u001b[39m*\u001b[39minit_inputs,\n\u001b[0;32m   1859\u001b[0m     token\u001b[39m=\u001b[39mtoken,\n\u001b[0;32m   1860\u001b[0m     cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[0;32m   1861\u001b[0m     local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1862\u001b[0m     _commit_hash\u001b[39m=\u001b[39mcommit_hash,\n\u001b[0;32m   1863\u001b[0m     _is_local\u001b[39m=\u001b[39mis_local,\n\u001b[0;32m   1864\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1865\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\cmu_10715_applied\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2017\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2015\u001b[0m \u001b[39m# Instantiate tokenizer.\u001b[39;00m\n\u001b[0;32m   2016\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2017\u001b[0m     tokenizer \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39minit_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit_kwargs)\n\u001b[0;32m   2018\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   2019\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m   2020\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to load vocabulary from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2021\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2022\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\cmu_10715_applied\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:194\u001b[0m, in \u001b[0;36mT5Tokenizer.__init__\u001b[1;34m(self, vocab_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, sp_model_kwargs, legacy, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_file \u001b[39m=\u001b[39m vocab_file\n\u001b[0;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extra_ids \u001b[39m=\u001b[39m extra_ids\n\u001b[1;32m--> 194\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msp_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_spm_processor()\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\cmu_10715_applied\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:200\u001b[0m, in \u001b[0;36mT5Tokenizer.get_spm_processor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    199\u001b[0m     sp_model \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 200\u001b[0m     model_pb2 \u001b[39m=\u001b[39m import_protobuf()\n\u001b[0;32m    201\u001b[0m     model \u001b[39m=\u001b[39m model_pb2\u001b[39m.\u001b[39mModelProto\u001b[39m.\u001b[39mFromString(sp_model)\n\u001b[0;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegacy:\n",
      "File \u001b[1;32mc:\\Users\\James\\anaconda3\\envs\\cmu_10715_applied\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:40\u001b[0m, in \u001b[0;36mimport_protobuf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m sentencepiece_model_pb2_new \u001b[39mas\u001b[39;00m sentencepiece_model_pb2\n\u001b[1;32m---> 40\u001b[0m \u001b[39mreturn\u001b[39;00m sentencepiece_model_pb2\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'sentencepiece_model_pb2' referenced before assignment"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tokenizer(ds[0][\"question\"][\"text\"], ds[0][\"document\"][\"summary\"][\"text\"], return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHO NORMALLY DELIVERS THE OPENING PROLOGUE IN THE PLAY?</s> The play begins with three pages disputing over the black cloak usually worn by the actor who delivers the prologue. They draw lots for the cloak, and one of the losers, Anaides, starts telling the audience what happens in the play to come; the others try to suppress him, interrupting him and putting their hands over his mouth. Soon they are fighting over the cloak and criticizing the author and the spectators as well. In the play proper, the goddess Diana, also called Cynthia, has ordained a \"solemn revels\" in the valley of Gargaphie in Greece. The gods Cupid and Mercury appear, and they too start to argue. Mercury has awakened Echo, who weeps for Narcissus, and states that a drink from Narcissus\\'s spring causes the drinkers to \"Grow dotingly enamored of themselves.\" The courtiers and ladies assembled for the Cynthia\\'s revels all drink from the spring. Asotus, a foolish spendthrift who longs to become a courtier and a master of fashion and manners, also drinks from the spring; emboldened by vanity and self-love, he challenges all comers to a competition of \"court compliment.\" The competition is held, in four phases, and the courtiers are beaten. Two symbolic masques are performed within the play for the assembled revelers. At their conclusion, Cynthia (representing Queen Elizabeth) has the dancers unmask and shows that vices have masqueraded as virtues. She sentences them to make reparation and to purify themselves by bathing in the spring at Mount Helicon. The figure of Actaeon in the play may represent Robert Devereux, 2nd Earl of Essex, while Cynthia\\'s lady in waiting Arete may be Lucy, Countess of Bedford, one of Elizabeth\\'s ladies in waiting as well as Jonson\\'s patroness. The play is notably rich in music, as is typical for the theatre of the boys\\' companies, which originated as church choirs.</s>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inp.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what happens in the play to come; the others try to suppress him, interrupting him and putting their hands over his mouth. Soon they are fighting over the cloak and criticizing the author and the spectators as well. In the play proper, the goddess Diana, also called Cynthia, has ordained a \"solemn revels\" in the valley of Gargaphie in Greece. The gods Cupid and Mercury appear, and they too start to argue. Mercury has awakened Echo'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "answer_offset = len(tokenizer(ds[0][\"question\"][\"text\"])[0])\n",
    "\n",
    "predict_answer_tokens = inp.input_ids[\n",
    "    0, answer_offset + answer_start_index : answer_offset + answer_end_index + 1\n",
    "]\n",
    "predicted = tokenizer.decode(predict_answer_tokens)\n",
    "predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmu_10715_applied",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
